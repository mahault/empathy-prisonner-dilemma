"""Tests for exploitability analysis module."""

import numpy as np
import pytest

from empathy.prisoners_dilemma.metrics import (
    ExploitabilityAnalysis,
    OutcomeClassifier,
    PayoffAnalysis,
    compute_best_response,
    compute_exploitability,
    classify_outcome,
)
from empathy.prisoners_dilemma.metrics.exploitability import (
    OutcomeType,
    OutcomeFrequencies,
    compute_expected_payoff,
    compute_payoffs_from_actions,
    compute_switching_rate,
    PD_PAYOFF_I,
    PD_PAYOFF_J,
    COOPERATE,
    DEFECT,
)


class TestPayoffMatrix:
    """Tests for payoff matrix correctness."""

    def test_pd_payoffs_cc(self):
        """CC should give (3, 3)."""
        assert PD_PAYOFF_I[COOPERATE, COOPERATE] == 3
        assert PD_PAYOFF_J[COOPERATE, COOPERATE] == 3

    def test_pd_payoffs_cd(self):
        """CD should give (0, 5) - sucker's payoff for i."""
        assert PD_PAYOFF_I[COOPERATE, DEFECT] == 0
        assert PD_PAYOFF_J[COOPERATE, DEFECT] == 5

    def test_pd_payoffs_dc(self):
        """DC should give (5, 0) - temptation for i."""
        assert PD_PAYOFF_I[DEFECT, COOPERATE] == 5
        assert PD_PAYOFF_J[DEFECT, COOPERATE] == 0

    def test_pd_payoffs_dd(self):
        """DD should give (1, 1)."""
        assert PD_PAYOFF_I[DEFECT, DEFECT] == 1
        assert PD_PAYOFF_J[DEFECT, DEFECT] == 1


class TestBestResponse:
    """Tests for best response computation."""

    def test_br_to_always_cooperate(self):
        """Best response to always cooperate is always defect."""
        opponent_policy = np.array([1.0, 0.0])  # Always cooperate
        br = compute_best_response(opponent_policy)

        # Should defect to get 5 instead of 3
        assert br[DEFECT] == 1.0
        assert br[COOPERATE] == 0.0

    def test_br_to_always_defect(self):
        """Best response to always defect is always defect."""
        opponent_policy = np.array([0.0, 1.0])  # Always defect
        br = compute_best_response(opponent_policy)

        # Should defect to get 1 instead of 0
        assert br[DEFECT] == 1.0
        assert br[COOPERATE] == 0.0

    def test_br_to_mixed_strategy(self):
        """Best response to 50/50 is defect."""
        opponent_policy = np.array([0.5, 0.5])
        br = compute_best_response(opponent_policy)

        # Expected payoff for C: 0.5*3 + 0.5*0 = 1.5
        # Expected payoff for D: 0.5*5 + 0.5*1 = 3.0
        # Should defect
        assert br[DEFECT] == 1.0


class TestExpectedPayoff:
    """Tests for expected payoff computation."""

    def test_mutual_cooperation(self):
        """Both cooperating should give 3 each."""
        policy_i = np.array([1.0, 0.0])
        policy_j = np.array([1.0, 0.0])

        payoff_i = compute_expected_payoff(policy_i, policy_j, PD_PAYOFF_I)
        assert np.isclose(payoff_i, 3.0)

    def test_mutual_defection(self):
        """Both defecting should give 1 each."""
        policy_i = np.array([0.0, 1.0])
        policy_j = np.array([0.0, 1.0])

        payoff_i = compute_expected_payoff(policy_i, policy_j, PD_PAYOFF_I)
        assert np.isclose(payoff_i, 1.0)

    def test_exploitation(self):
        """i defects, j cooperates: i gets 5."""
        policy_i = np.array([0.0, 1.0])
        policy_j = np.array([1.0, 0.0])

        payoff_i = compute_expected_payoff(policy_i, policy_j, PD_PAYOFF_I)
        assert np.isclose(payoff_i, 5.0)

    def test_mixed_strategy_payoff(self):
        """Test expected payoff with mixed strategies."""
        policy_i = np.array([0.5, 0.5])
        policy_j = np.array([0.5, 0.5])

        payoff_i = compute_expected_payoff(policy_i, policy_j, PD_PAYOFF_I)
        # E = 0.25*3 + 0.25*0 + 0.25*5 + 0.25*1 = 2.25
        assert np.isclose(payoff_i, 2.25)


class TestExploitability:
    """Tests for exploitability computation."""

    def test_always_defect_not_exploitable(self):
        """Always defect (Nash) should have zero exploitability."""
        policy = np.array([0.0, 1.0])
        exploit = compute_exploitability(policy)

        # Nash equilibrium - opponent's BR is also defect
        # No improvement possible over Nash
        assert np.isclose(exploit, 0.0)

    def test_always_cooperate_highly_exploitable(self):
        """Always cooperate should be highly exploitable."""
        policy = np.array([1.0, 0.0])
        exploit = compute_exploitability(policy)

        # Opponent's BR is defect, getting 5 instead of Nash's 1
        # Exploitability = 5 - 1 = 4
        assert exploit > 0.0
        assert np.isclose(exploit, 4.0)

    def test_exploitability_increases_with_cooperation(self):
        """Higher cooperation rate should mean higher exploitability."""
        low_coop = np.array([0.2, 0.8])
        high_coop = np.array([0.8, 0.2])

        exploit_low = compute_exploitability(low_coop)
        exploit_high = compute_exploitability(high_coop)

        assert exploit_high > exploit_low


class TestOutcomeFrequencies:
    """Tests for outcome frequency computation."""

    def test_all_cc(self):
        """All CC should give CC=1.0."""
        actions_i = np.array([COOPERATE] * 10)
        actions_j = np.array([COOPERATE] * 10)

        freq = OutcomeFrequencies.from_actions(actions_i, actions_j)

        assert np.isclose(freq.CC, 1.0)
        assert np.isclose(freq.CD, 0.0)
        assert np.isclose(freq.DC, 0.0)
        assert np.isclose(freq.DD, 0.0)

    def test_all_dd(self):
        """All DD should give DD=1.0."""
        actions_i = np.array([DEFECT] * 10)
        actions_j = np.array([DEFECT] * 10)

        freq = OutcomeFrequencies.from_actions(actions_i, actions_j)

        assert np.isclose(freq.DD, 1.0)
        assert np.isclose(freq.CC, 0.0)

    def test_mixed_outcomes(self):
        """Test mixed outcomes."""
        actions_i = np.array([COOPERATE, COOPERATE, DEFECT, DEFECT])
        actions_j = np.array([COOPERATE, DEFECT, COOPERATE, DEFECT])

        freq = OutcomeFrequencies.from_actions(actions_i, actions_j)

        assert np.isclose(freq.CC, 0.25)
        assert np.isclose(freq.CD, 0.25)
        assert np.isclose(freq.DC, 0.25)
        assert np.isclose(freq.DD, 0.25)

    def test_frequencies_sum_to_one(self):
        """Frequencies should always sum to 1."""
        np.random.seed(42)
        actions_i = np.random.choice([COOPERATE, DEFECT], size=100)
        actions_j = np.random.choice([COOPERATE, DEFECT], size=100)

        freq = OutcomeFrequencies.from_actions(actions_i, actions_j)

        total = freq.CC + freq.CD + freq.DC + freq.DD
        assert np.isclose(total, 1.0)


class TestOutcomeClassification:
    """Tests for outcome classification."""

    def test_classify_mutual_cooperation(self):
        """High CC rate should classify as mutual cooperation."""
        actions_i = np.array([COOPERATE] * 100)
        actions_j = np.array([COOPERATE] * 100)

        outcome = classify_outcome(actions_i, actions_j)

        assert outcome == OutcomeType.MUTUAL_COOPERATION

    def test_classify_mutual_defection(self):
        """High DD rate should classify as mutual defection."""
        actions_i = np.array([DEFECT] * 100)
        actions_j = np.array([DEFECT] * 100)

        outcome = classify_outcome(actions_i, actions_j)

        assert outcome == OutcomeType.MUTUAL_DEFECTION

    def test_classify_i_exploited(self):
        """i cooperates, j defects -> i exploited."""
        actions_i = np.array([COOPERATE] * 100)
        actions_j = np.array([DEFECT] * 100)

        outcome = classify_outcome(actions_i, actions_j)

        assert outcome == OutcomeType.I_EXPLOITED

    def test_classify_j_exploited(self):
        """j cooperates, i defects -> j exploited."""
        actions_i = np.array([DEFECT] * 100)
        actions_j = np.array([COOPERATE] * 100)

        outcome = classify_outcome(actions_i, actions_j)

        assert outcome == OutcomeType.J_EXPLOITED

    def test_classify_cycling(self):
        """Alternating actions should classify as cycling."""
        actions_i = np.array([COOPERATE, DEFECT] * 50)
        actions_j = np.array([DEFECT, COOPERATE] * 50)

        outcome = classify_outcome(actions_i, actions_j)

        assert outcome == OutcomeType.CYCLING


class TestSwitchingRate:
    """Tests for switching rate computation."""

    def test_no_switching(self):
        """Constant actions should have 0 switching rate."""
        actions = np.array([COOPERATE] * 10)
        rate = compute_switching_rate(actions)
        assert np.isclose(rate, 0.0)

    def test_all_switching(self):
        """Alternating actions should have 1.0 switching rate."""
        actions = np.array([COOPERATE, DEFECT] * 5)
        rate = compute_switching_rate(actions)
        assert np.isclose(rate, 1.0)

    def test_half_switching(self):
        """Test intermediate switching rate."""
        actions = np.array([COOPERATE, COOPERATE, DEFECT, DEFECT, COOPERATE])
        # Switches at positions 2->3 and 4->5: 2 switches out of 4 transitions
        rate = compute_switching_rate(actions)
        assert np.isclose(rate, 0.5)


class TestPayoffAnalysis:
    """Tests for PayoffAnalysis class."""

    def test_cumulative_payoffs(self):
        """Test cumulative payoff computation."""
        actions_i = np.array([COOPERATE, COOPERATE, DEFECT])
        actions_j = np.array([COOPERATE, DEFECT, DEFECT])

        cum_i, cum_j = PayoffAnalysis.compute_cumulative_payoffs(actions_i, actions_j)

        # Round 1: CC -> i:3, j:3
        # Round 2: CD -> i:0, j:5
        # Round 3: DD -> i:1, j:1
        assert np.allclose(cum_i, [3, 3, 4])
        assert np.allclose(cum_j, [3, 8, 9])

    def test_average_payoffs(self):
        """Test average payoff computation."""
        actions_i = np.array([COOPERATE] * 100)
        actions_j = np.array([COOPERATE] * 100)

        avg_i, avg_j = PayoffAnalysis.compute_average_payoffs(actions_i, actions_j)

        assert np.isclose(avg_i, 3.0)
        assert np.isclose(avg_j, 3.0)

    def test_pareto_efficiency(self):
        """Test Pareto efficiency computation."""
        # Mutual cooperation is Pareto optimal
        actions_cc_i = np.array([COOPERATE] * 100)
        actions_cc_j = np.array([COOPERATE] * 100)
        eff_cc = PayoffAnalysis.pareto_efficiency(actions_cc_i, actions_cc_j)
        assert np.isclose(eff_cc, 1.0)

        # Mutual defection is worst
        actions_dd_i = np.array([DEFECT] * 100)
        actions_dd_j = np.array([DEFECT] * 100)
        eff_dd = PayoffAnalysis.pareto_efficiency(actions_dd_i, actions_dd_j)
        assert np.isclose(eff_dd, 0.0)


class TestExploitabilityAnalysis:
    """Tests for ExploitabilityAnalysis class."""

    def test_analyze_trajectory(self):
        """Test full trajectory analysis."""
        actions_i = np.array([COOPERATE] * 50 + [DEFECT] * 50)
        actions_j = np.array([COOPERATE] * 50 + [DEFECT] * 50)

        analyzer = ExploitabilityAnalysis()
        stats = analyzer.analyze_trajectory(actions_i, actions_j)

        assert 0.0 <= stats.cooperation_rate_i <= 1.0
        assert 0.0 <= stats.cooperation_rate_j <= 1.0
        assert stats.outcome_type in OutcomeType
        assert stats.exploitability_i >= 0.0
        assert stats.exploitability_j >= 0.0

    def test_analyze_multiple_trajectories(self):
        """Test multi-trajectory analysis."""
        trajectories = [
            (np.array([COOPERATE] * 20), np.array([COOPERATE] * 20)),
            (np.array([DEFECT] * 20), np.array([DEFECT] * 20)),
            (np.array([COOPERATE] * 20), np.array([DEFECT] * 20)),
        ]

        analyzer = ExploitabilityAnalysis()
        results = analyzer.analyze_multiple_trajectories(trajectories)

        assert results["n_trajectories"] == 3
        assert "outcome_distribution" in results
        assert "mean_payoff_i" in results
        assert "mean_exploitability_i" in results

    def test_exploitability_curve(self):
        """Test exploitability curve generation."""
        coop_rates, exploitability = ExploitabilityAnalysis.exploitability_curve()

        assert len(coop_rates) == 101
        assert len(exploitability) == 101
        assert coop_rates[0] == 0.0
        assert coop_rates[-1] == 1.0

        # Exploitability should increase with cooperation rate
        assert exploitability[-1] > exploitability[0]


class TestOutcomeClassifier:
    """Tests for OutcomeClassifier class."""

    def test_classifier_with_custom_thresholds(self):
        """Test classifier with custom thresholds."""
        classifier = OutcomeClassifier(
            cooperation_threshold=0.5,  # Lower threshold
        )

        # 60% CC should now classify as mutual cooperation
        actions_i = np.array([COOPERATE] * 60 + [DEFECT] * 40)
        actions_j = np.array([COOPERATE] * 60 + [DEFECT] * 40)

        outcome = classifier.classify(actions_i, actions_j)

        # With lower threshold, this should be mutual cooperation
        # (CC rate is 0.36, which is less than 0.5, so still cycling)
        # Actually need to construct proper CC outcomes
        actions_i = np.array([COOPERATE] * 100)
        actions_j = np.array([COOPERATE] * 60 + [DEFECT] * 40)
        # This gives CC=0.6, CD=0.4

        # Let's use all-cooperate for simplicity
        actions_i = np.array([COOPERATE] * 100)
        actions_j = np.array([COOPERATE] * 100)
        outcome = classifier.classify(actions_i, actions_j)
        assert outcome == OutcomeType.MUTUAL_COOPERATION

    def test_classify_with_details(self):
        """Test classification with detailed statistics."""
        classifier = OutcomeClassifier()

        actions_i = np.array([COOPERATE] * 80 + [DEFECT] * 20)
        actions_j = np.array([COOPERATE] * 80 + [DEFECT] * 20)

        details = classifier.classify_with_details(actions_i, actions_j)

        assert "outcome_type" in details
        assert "cooperation_rate_i" in details
        assert "cooperation_rate_j" in details
        assert "outcome_frequencies" in details
        assert "payoff_gap" in details


class TestIntegrationWithSimulation:
    """Integration tests with simulation results."""

    def test_analyze_simulation_history(self):
        """Test analysis of simulation-like history."""
        # Simulate a trajectory where agents learn to cooperate
        np.random.seed(42)
        T = 100
        actions_i = []
        actions_j = []

        # Start with random, converge to cooperation
        for t in range(T):
            if t < 30:
                actions_i.append(np.random.choice([COOPERATE, DEFECT]))
                actions_j.append(np.random.choice([COOPERATE, DEFECT]))
            else:
                # Converge to cooperation
                actions_i.append(COOPERATE)
                actions_j.append(COOPERATE)

        actions_i = np.array(actions_i)
        actions_j = np.array(actions_j)

        analyzer = ExploitabilityAnalysis()
        stats = analyzer.analyze_trajectory(actions_i, actions_j)

        # Should have moderate cooperation rate (high in second half)
        assert stats.cooperation_rate_i > 0.5
        assert stats.cooperation_rate_j > 0.5


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
